{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the random number generator\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "# Ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data from h5py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('SVHN_single_grey1.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = file['X_train'][:]\n",
    "y_train = file['y_train'][:]\n",
    "x_test  = file['X_test'][:]\n",
    "y_test  = file['y_test'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing shape and some values of label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 32, 32)\n",
      "(42000,)\n",
      "(18000, 32, 32)\n",
      "(18000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x_train, x_test: uint8 array of grayscale image data with shape (num_samples, 32,32)\n",
    "### y_train, y_test: uint8 array of digit labels (integers in range 0-9) with shape (num_samples,).\n",
    "### There are 42000 samples in training data each sample with dimension 32*32\n",
    "### There are 18000 samples in testing data each sample with dimension 32*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254.9745\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(x_train.max())\n",
    "print(x_train.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train and x_test contain greyscale RGB codes (from 0 to 255) while y_train and y_test contains labels from 0 to 9 which represents which number they actually are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 examples are:  [2 6 7 4 4]\n"
     ]
    }
   ],
   "source": [
    "print('First 5 examples are: ', y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label is 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b8acc330c8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print('The label is {}'.format(y_train[8000]))\n",
    "plt.imshow(x_train[8000],cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label is 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b8a11b3908>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWXElEQVR4nO2dX4yUZZbGnyNC86dboAGbDi00oyRIJitKh7gZY9yZjFEyCZpsjF4YL8ww2YzJmsxeGDdZ3WQvnM2q8WLjBlcyzMb1z44ayYbsjppJzNw4NK4giDgoqDRt0wINCMjfsxf1kTSkzlPVb1V91fg+v4RQ/Z16v+/UW9/T1f0+fc5r7g4hxPefq9qdgBCiHCR2ITJBYhciEyR2ITJBYhciEyR2ITLh6kYGm9ldAJ4DMAXAv7v7U+z53d3d3tfX18glL79+087Vjusx2zPVEo1yvOqq+Pt66rWabduy85X9XjebZs9VNB9fffUVDh8+XDWYLHYzmwLgXwH8FMB+AFvMbJO7fxyN6evrw+bNm6vGUt7oq6+O02c3R+rER4Jh12IiO3fuXBj77rvvwhi73rRp06oe7+joCMdcuHAhjDFY/tEcs2uxGJvHKVOmTDiPsmFzlUI0H3fffXc8poHrrQawx90/d/czAF4BsLaB8wkhWkgjYl8E4KtxX+8vjgkhJiEtX6Azs3VmNmhmg4cPH2715YQQAY2IfQjAdeO+7iuOXYK7r3f3AXcf6O7ubuByQohGaETsWwAsM7OlZjYNwP0ANjUnLSFEs0lejXf3c2b2CID/RcV62+DuO5uWWR2w1Vu2Yp1q46SsWp8+fTqMpa4ws1h0TrYazFyNVKK5Yq+ZxVrhruRGQ++yu28GUN1LE0JMKvQXdEJkgsQuRCZI7EJkgsQuRCZI7EJkQvM9l0RS7LDz588nnY9ZPIzITkqxwoC0gpZaROdMnStma509ezaMRVYfm6upU6eGsVTKtOVSLd3oHkkpGmKvV5/sQmSCxC5EJkjsQmSCxC5EJkjsQmTCpFmNZzR7RTW1DVO0appa0MJWs8+cORPG2Mp6s2E5stZZ0ThWdMPeF+ZOsHNeCUUyKfdjdF9RF2rCVxFCXJFI7EJkgsQuRCZI7EJkgsQuRCZI7EJkwhVhvUXWRGrhQWrhR2R5MeuEWW/MXjt+/HgYY33tousxe3D27NlhjFlvJ0+enPA4VuySuv0Tm+MUUu+P1BxTds9Juff1yS5EJkjsQmSCxC5EJkjsQmSCxC5EJkjsQmRCQ9abme0DcBzAeQDn3H2gxvOTbJKoqoltadSKaqcoj46OjnAMs0hY1djo6GgYY7ZcZA8ye23mzJlhjFl2zBqKbDn2nrE8UqveovuN5cFi7P1k88EszCh/9ppTKuWa4bP/lbt/04TzCCFaiH6MFyITGhW7A/i9mW01s3XNSEgI0Roa/TH+NncfMrNrAbxtZp+4+3vjn1B8E1gHAIsWLWrwckKIVBr6ZHf3oeL/gwDeBLC6ynPWu/uAuw/MmzevkcsJIRogWexmNsvMui4+BnAngB3NSkwI0Vwa+TG+B8CbhRVxNYD/dPf/qTUosnKYpRFVSjHLhdlaqXZSZLFNnz49HMNssmPHjoWxL7/8MumckcXT398fjmH5M06cOBHGovy/+SY2bnp6esJYZ2dnGGO2YnTvnDp1KhzDbLLUqj1WqRidk9nUKU1Hk8Xu7p8DuCl1vBCiXGS9CZEJErsQmSCxC5EJErsQmSCxC5EJV0TDyWY3emQWScrebMyq2b9/fxjbtWtXGNu9e3cYY3R3d1c9zuy1GTNmhDFmDw4PD4exTz/9tOrxw4cPh2MYS5YsCWNz5swJY9E9wqwwdl8xu5eRMi61oWqEPtmFyASJXYhMkNiFyASJXYhMkNiFyIQrejU+dbsdVkSQMu7QoUPhmGhVGgC2bt0axvbu3RvG2Orz/PnzJzyG9VxjRTdsNX7Pnj1Vj7PeeiyPvr6+MLZw4cIwFsEcGbYan7r9Eyu+Sll1T+mxqE92ITJBYhciEyR2ITJBYhciEyR2ITJBYhciE0q13swsqQdd1E+O9QNLtd5YwcKZM2eqHk+13nbu3BnGRkZGwtiyZcvCWFdXV9XjCxYsCMeweYxeMwAcOXIkjEW95sbGxsIxrDgl1dZK2TosdYunlG2o2PXY3Ef5M0tOn+xCZILELkQmSOxCZILELkQmSOxCZILELkQm1LTezGwDgJ8BOOjuPyyOdQN4FUA/gH0A7nP32IepA2Z3JFX4EDsmNRbZHUePHg3HHDhwIIwNDQ2FMWa7MBsn6kF37bXXhmO+/fbbMMaq1Jg9GPWaY9susXsg2noLAGbNmhXGIluRWW+pVZGpPREj2H3fqqq33wC467JjjwF4192XAXi3+FoIMYmpKfZiv/XLv02vBbCxeLwRwD3NTUsI0WxSf2fvcfeLnQu+RmVHVyHEJKbhBTqv/PIQ/gJhZuvMbNDMBtmflQohWkuq2EfMrBcAiv8PRk909/XuPuDuA/PmzUu8nBCiUVLFvgnAQ8XjhwC81Zx0hBCtoh7r7WUAdwCYb2b7ATwB4CkAr5nZwwC+AHBfo4k022ZIJaVajllXbPskNo7lwaqrosaS11xzTTiGWU1z584NY4sXLw5j0a9szHrr7+8PY+ynQra1VTRXzNpksdQtmdi4KJbSFJONqSl2d38gCP2k1lghxORBf0EnRCZI7EJkgsQuRCZI7EJkgsQuRCaUvtdbis0QNVFkltHJkyfDGLNq2N5m27Ztq3r8nXfeCcfs2LEjjLH8Ozs7wxirYIssqtQquhUrVoSxnp74r6TvvPPOqsenTZsWjmGVbSzHqCEpAJw9ezaMRTBrk1lorJKO5RG97pRGmrQxZxgRQnyvkNiFyASJXYhMkNiFyASJXYhMkNiFyITSrbcUIluuFdVwzA6L7Ctma6VYP0C6/RPlz3JkNh+zf9j8R40eUyrUAG5rpVSHpTYdTbUOowacjNQKuwh9sguRCRK7EJkgsQuRCRK7EJkgsQuRCaWuxrt70up0SvFMK1bqT58+XfU4K7phRRps5Z/BVouj1We2Gs/yZ+Oi+QBiF4JtkTRz5swwxlbqWSwqoGH3IcuRxdhKPXvPmr3qHuZQylWEEG1HYhciEyR2ITJBYhciEyR2ITJBYhciE+rZ/mkDgJ8BOOjuPyyOPQng5wBGi6c97u6b67lgZDOwQofIPmE2CIONS9kWiFlXJ06cqD+xcbCea1GRCRBbjizH1O2r2Dmj95ltQ8UsKDYuxXpj9wB7z9h9ymIp9hqzj1POV88n+28A3FXl+LPuvrL4V5fQhRDto6bY3f09ABOvzxNCTCoa+Z39ETPbbmYbzCze6lMIMSlIFfvzAK4HsBLAMICnoyea2TozGzSzwWgbXyFE60kSu7uPuPt5d78A4AUAq8lz17v7gLsPsD22hRCtJUnsZtY77st7AcTbngghJgX1WG8vA7gDwHwz2w/gCQB3mNlKAA5gH4Bf1HvBFLsspQcdsyZYjJ0zqvJilW3MjmEw641VUKX0yWOxkZGRMHbgwIEwFs3JjBkzwjFLly4NY4sXLw5jbDusqOddam+91Pc65X5kOaZQU+zu/kCVwy82NQshRMvRX9AJkQkSuxCZILELkQkSuxCZILELkQmlN5xMabIYjUmtekttVBlZK8yOYbHULZ4YKVVv7DWzbYs++eSTMDY6Olr1OHvP9u7dG8ZWrVoVxm666aYwFlXLMWsz1bZl52T3fVnWmz7ZhcgEiV2ITJDYhcgEiV2ITJDYhcgEiV2ITCjVejOzpAaAkQXBrAm2lxezmti4yEZje54xyyXVemN7inV0dFQ9PmfOnHAMazjZ1dUVxtjr3r17d9XjY2Nj4ZiDBw+Gsah6DQBmz54dxm688caqx9m+cuxeTNnfDuDvWVR1yO6BlGpKfbILkQkSuxCZILELkQkSuxCZILELkQmlrsYDcbEAKyKIYqn93Zq9rQ6DbdXEYCv10Yo7i7HVZ7ZSPH/+/KQ8jhw5UvX4Z599Fo5hrkBvb28YW758eRiL3uvUHn9spZ7dj8xNiFbjU7a1YuiTXYhMkNiFyASJXYhMkNiFyASJXYhMkNiFyIR6tn+6DsBvAfSgst3Tend/zsy6AbwKoB+VLaDuc/fqfksdMLsjssNSe4Wl9hHr7Oysejzqc1brfCwPZrsw+ycqvGG20IIFC8LY8ePHwxjbqDOaK8apU6eS8jhx4sSEY7NmzQrHsOIldp+y94wVyUT3AdsqK8qR5VfPJ/s5AL9y9xUAbgXwSzNbAeAxAO+6+zIA7xZfCyEmKTXF7u7D7v5B8fg4gF0AFgFYC2Bj8bSNAO5pUY5CiCYwod/ZzawfwM0A3gfQ4+7DRehrVH7MF0JMUuoWu5l1AngdwKPufmx8zCt/k1j17xLNbJ2ZDZrZIOtBLoRoLXWJ3cymoiL0l9z9jeLwiJn1FvFeAFXbjLj7encfcPeB7u7uZuQshEigptitslT4IoBd7v7MuNAmAA8Vjx8C8Fbz0xNCNIt6qt5+BOBBAB+Z2YfFsccBPAXgNTN7GMAXAO6rdSIza/qWNikwO4xVJ6VYb6zajNlhqVtURbB5Z1tUMTsspeqQ2VMsR2aHMest2vYqqjQD0uYXSO8ZF80JqypkvfDC69R6grv/EUD0Kn4y4SsKIdpC+z9mhRClILELkQkSuxCZILELkQkSuxCZUHrDyRTrLWX7p9TqJFZpFFlsc+fODcew6ipmGbEqqRTbiNk4KdtJAdxWjLaNYmOY7ckad6Y0CWX3B7Pe2FwxSzeyAIHYlmN2HbMiI/TJLkQmSOxCZILELkQmSOxCZILELkQmSOxCZELp1ltESoPI1OokZr2xPCJbjjVXZFYTs95YJRobFzWjZJYRa2DJYozovWGWUWolWoqtyOaDkVqpyF53NI7NRxRj75c+2YXIBIldiEyQ2IXIBIldiEyQ2IXIhNJX46PV7mYWyNQidYU5Ku5YuHBhOKanJ26nz/q7MdjKbrNX41NXyKPrsX59s2fPDmNsi6qUHoCsaCVlfoH0wqxohZ85MlGO7D3RJ7sQmSCxC5EJErsQmSCxC5EJErsQmSCxC5EJNa03M7sOwG9R2ZLZAax39+fM7EkAPwcwWjz1cXffXOt8KbYX6z8WwSwIZiex/BYtWlT1+Jo1a8IxbDPLLVu2hLGhoaEwxvIfHR2tenxsbCwcw4p12LijR4+GsYhoDgFg1apVYez2228PY8uXLw9j0WtjBS0phUYA718Y2bbsemyLJ1bMFY6p4znnAPzK3T8wsy4AW83s7SL2rLv/y4SvKoQonXr2ehsGMFw8Pm5muwDE356FEJOSCf3Obmb9AG4G8H5x6BEz225mG8ws7qcshGg7dYvdzDoBvA7gUXc/BuB5ANcDWInKJ//Twbh1ZjZoZoOHDh1qPGMhRBJ1id3MpqIi9Jfc/Q0AcPcRdz/v7hcAvABgdbWx7r7e3QfcfWDevHnNylsIMUFqit0qlSsvAtjl7s+MO9477mn3AtjR/PSEEM2intX4HwF4EMBHZvZhcexxAA+Y2UpU7Lh9AH7RSCKsKiiymlK2wAF4nzlWDRX1OmM96Pr7+8MY+7WG5ciqw6K5YtdiFg+zqFge0etm51uxYsWEzwfw7bei94bZuam95FL72kWwezG6FrPk6lmN/yOAandeTU9dCDF50F/QCZEJErsQmSCxC5EJErsQmSCxC5EJk2b7J2Z3RHYNs0GYdcWuxSyZyHpjFtScOXPC2OLFi5PyYA0WIxuKWTLM4mF/CLVkyZIwlnItNh9sHtn8R5Vozd7WCuDViMxyPHv2bNXj7B5Isfn0yS5EJkjsQmSCxC5EJkjsQmSCxC5EJkjsQmTCFWG9RTFmnzDbgtlyjOickSUHADfccEMYYw0Ke3t7wxizcaIc2b5ybO6ZZcdyjBo9Mtuwr68vjLFxLP+ooo/Ztmx+mb3GKjdTKgtT9tLTXm9CCIldiFyQ2IXIBIldiEyQ2IXIBIldiEwo3XqL7DJmh0WWxvTp0yc8BoirjABuu0R2B7PQWHUSqwBjlVzMRovmkVmRzIaaNWvWhK8FxNV3rHqN2WvMZmXvWfTa2PnYfLBYqhUc3avs/ohiVEdhRAjxvUJiFyITJHYhMkFiFyITJHYhMqHmaryZTQfwHoCO4vm/c/cnzGwpgFcAzAOwFcCD7h5XCdSA/gF/sFrJijTYqmTK6i2LpW4XxFa62So+K6qIVoTZyi47H9vairkh0Tm7urrCManvGXNeUlbjU3sUpp4zpdArml82pp5P9tMAfuzuN6GyPfNdZnYrgF8DeNbdbwBwBMDDdZxLCNEmaordK3xbfDm1+OcAfgzgd8XxjQDuaUWCQojmUO/+7FOKHVwPAngbwGcAxtz94s9W+wEsakmGQoimUJfY3f28u68E0AdgNYDl9V7AzNaZ2aCZDbJtg4UQrWVCq/HuPgbgDwD+EsAcM7u4QtYHYCgYs97dB9x9gG04IIRoLTXFbmYLzGxO8XgGgJ8C2IWK6P+6eNpDAN5qUY5CiCZQTyFML4CNZjYFlW8Or7n7f5vZxwBeMbN/AvB/AF6s64KBXcbskyjW7F5ytc4ZFdAcPXo0HJO67RKztVjPuyhH1jsttdiF2YPR607t/cYspZStnJgVxl5zSsEWwF9biiZSqCl2d98O4OYqxz9H5fd3IcQVgP6CTohMkNiFyASJXYhMkNiFyASJXYhMMGZBNP1iZqMAvii+nA/gm9IuHqM8LkV5XMqVlscSd19QLVCq2C+5sNmguw+05eLKQ3lkmId+jBciEyR2ITKhnWJf38Zrj0d5XIryuJTvTR5t+51dCFEu+jFeiExoi9jN7C4z221me8zssXbkUOSxz8w+MrMPzWywxOtuMLODZrZj3LFuM3vbzP5c/F99/6TW5/GkmQ0Vc/Khma0pIY/rzOwPZvaxme00s78tjpc6JySPUufEzKab2Z/MbFuRxz8Wx5ea2fuFbl41s7jssBruXuo/AFNQaWv1AwDTAGwDsKLsPIpc9gGY34br3g7gFgA7xh37ZwCPFY8fA/DrNuXxJIC/K3k+egHcUjzuAvApgBVlzwnJo9Q5AWAAOovHUwG8D+BWAK8BuL84/m8A/mYi523HJ/tqAHvc/XOvtJ5+BcDaNuTRNtz9PQCHLzu8FpXGnUBJDTyDPErH3Yfd/YPi8XFUmqMsQslzQvIoFa/Q9Cav7RD7IgBfjfu6nc0qHcDvzWyrma1rUw4X6XH34eLx1wB62pjLI2a2vfgxv+W/TozHzPpR6Z/wPto4J5flAZQ8J61o8pr7At1t7n4LgLsB/NLMbm93QkDlOzsq34jawfMArkdlj4BhAE+XdWEz6wTwOoBH3f3Y+FiZc1Ilj9LnxBto8hrRDrEPAbhu3Ndhs8pW4+5Dxf8HAbyJ9nbeGTGzXgAo/j/YjiTcfaS40S4AeAElzYmZTUVFYC+5+xvF4dLnpFoe7ZqT4tpjmGCT14h2iH0LgGXFyuI0APcD2FR2EmY2y8y6Lj4GcCeAHXxUS9mESuNOoI0NPC+Kq+BelDAnVmns9iKAXe7+zLhQqXMS5VH2nLSsyWtZK4yXrTauQWWl8zMAf9+mHH6AihOwDcDOMvMA8DIqPw6eReV3r4dR2TPvXQB/BvAOgO425fEfAD4CsB0VsfWWkMdtqPyIvh3Ah8W/NWXPCcmj1DkB8BeoNHHdjso3ln8Yd8/+CcAeAP8FoGMi59Vf0AmRCbkv0AmRDRK7EJkgsQuRCRK7EJkgsQuRCRK7EJkgsQuRCRK7EJnw/430S5pLYt1RAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print('The label is {}'.format(y_train[1000]))\n",
    "plt.imshow(x_train[1000],cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are some distractors in the image samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape features\n",
    "- reshape() method gives a new shape to an array without changing its data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024)\n",
      "(18000, 1024)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(42000, 1024)\n",
    "print(x_train.shape)\n",
    "x_test = x_test.reshape(18000, 1024)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize features\n",
    "- Normalize features from 0-255 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254.9745\n",
      "0.0\n",
      "0.9999\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(x_train.max())\n",
    "print(x_train.min())\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "print(x_train.max())\n",
    "print(x_train.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### One-hot encoding for the class vector\n",
    "- convert class vectors (integers) to binary class matrix\n",
    "- convert x_train and x_test\n",
    "- number of classes: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[10])\n",
    "y_train = to_categorical(y_train,num_classes=10)\n",
    "y_test = to_categorical(y_test,num_classes=10)\n",
    "print(y_train[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize & building  the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "- The Sequential model is a linear stack of layers.\n",
    "- The model needs to know what input shape it should expect. For this reason, the first layer in a Sequential model (and only the first, because following layers can do automatic shape inference) needs to receive information about its input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the sequential model\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening layer\n",
    "classifier.add(Dense(400, input_shape=(1024,), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers\n",
    "classifier.add(Dense(activation = 'relu', units = 400, kernel_initializer='uniform',name='Layer_1'))\n",
    "classifier.add(Dense(activation = 'relu', units = 200, kernel_initializer='uniform',name='Layer_2'))\n",
    "\n",
    "# Dropout layer\n",
    "classifier.add(Dropout(0.5))\n",
    "\n",
    "# Hidden layers\n",
    "classifier.add(Dense(activation = 'relu', units = 100, kernel_initializer='uniform',name='Layer_3'))\n",
    "classifier.add(Dense(activation = 'relu', units = 50, kernel_initializer='uniform',name='Layer_4'))\n",
    "\n",
    "# Dropout layer\n",
    "classifier.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output layer\n",
    "classifier.add(Dense(10, activation='softmax', name='Output'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize the model\n",
    "- model.summary() prints a summary representation of the model. For layers with multiple outputs, multiple is displayed instead of each individual output shape due to size limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 400)               410000    \n",
      "_________________________________________________________________\n",
      "Layer_1 (Dense)              (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "Layer_2 (Dense)              (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "Layer_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "Layer_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 676,260\n",
      "Trainable params: 676,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model\n",
    "- .fit() trains the model for a fixed number of epochs (iterations on a dataset)\n",
    "- batch_size is the number of samples per gradient update\n",
    "- validation_data is the data on which to evaluate the loss and any model metrics at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/30\n",
      "42000/42000 [==============================] - 8s 179us/sample - loss: 2.3031 - accuracy: 0.0977 - val_loss: 2.3026 - val_accuracy: 0.0955\n",
      "Epoch 2/30\n",
      "42000/42000 [==============================] - 7s 171us/sample - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3029 - val_accuracy: 0.0955\n",
      "Epoch 3/30\n",
      "42000/42000 [==============================] - 7s 169us/sample - loss: 2.3027 - accuracy: 0.1006 - val_loss: 2.3029 - val_accuracy: 0.0982\n",
      "Epoch 4/30\n",
      "42000/42000 [==============================] - 7s 176us/sample - loss: 2.3027 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.1002\n",
      "Epoch 5/30\n",
      "42000/42000 [==============================] - 7s 175us/sample - loss: 2.3028 - accuracy: 0.0987 - val_loss: 2.3027 - val_accuracy: 0.0955\n",
      "Epoch 6/30\n",
      "42000/42000 [==============================] - 8s 179us/sample - loss: 2.3027 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.0955\n",
      "Epoch 7/30\n",
      "42000/42000 [==============================] - 7s 173us/sample - loss: 2.3027 - accuracy: 0.1004 - val_loss: 2.3028 - val_accuracy: 0.0955\n",
      "Epoch 8/30\n",
      "42000/42000 [==============================] - 7s 175us/sample - loss: 2.3028 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0982\n",
      "Epoch 9/30\n",
      "42000/42000 [==============================] - 8s 180us/sample - loss: 2.3028 - accuracy: 0.0995 - val_loss: 2.3028 - val_accuracy: 0.0955\n",
      "Epoch 10/30\n",
      "42000/42000 [==============================] - 8s 193us/sample - loss: 2.3028 - accuracy: 0.1008 - val_loss: 2.3028 - val_accuracy: 0.0955\n",
      "Epoch 11/30\n",
      "42000/42000 [==============================] - 8s 188us/sample - loss: 2.3027 - accuracy: 0.1005 - val_loss: 2.3028 - val_accuracy: 0.0955\n",
      "Epoch 12/30\n",
      "42000/42000 [==============================] - 8s 191us/sample - loss: 2.3028 - accuracy: 0.1015 - val_loss: 2.3027 - val_accuracy: 0.0982\n",
      "Epoch 13/30\n",
      "42000/42000 [==============================] - 8s 187us/sample - loss: 2.3028 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.1002\n",
      "Epoch 14/30\n",
      "42000/42000 [==============================] - 8s 192us/sample - loss: 2.3028 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.1002\n",
      "Epoch 15/30\n",
      "42000/42000 [==============================] - 8s 186us/sample - loss: 2.3028 - accuracy: 0.1002 - val_loss: 2.3026 - val_accuracy: 0.1008\n",
      "Epoch 16/30\n",
      "42000/42000 [==============================] - 8s 186us/sample - loss: 2.3027 - accuracy: 0.1002 - val_loss: 2.3029 - val_accuracy: 0.0955\n",
      "Epoch 17/30\n",
      "42000/42000 [==============================] - 8s 189us/sample - loss: 2.3028 - accuracy: 0.1004 - val_loss: 2.3028 - val_accuracy: 0.0955\n",
      "Epoch 18/30\n",
      "42000/42000 [==============================] - 8s 190us/sample - loss: 2.3028 - accuracy: 0.0999 - val_loss: 2.3028 - val_accuracy: 0.0955\n",
      "Epoch 19/30\n",
      "42000/42000 [==============================] - 8s 193us/sample - loss: 2.3028 - accuracy: 0.0995 - val_loss: 2.3029 - val_accuracy: 0.0955\n",
      "Epoch 20/30\n",
      "42000/42000 [==============================] - 8s 182us/sample - loss: 2.3028 - accuracy: 0.0989 - val_loss: 2.3027 - val_accuracy: 0.0955\n",
      "Epoch 21/30\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3028 - val_accuracy: 0.0982\n",
      "Epoch 22/30\n",
      "42000/42000 [==============================] - 8s 187us/sample - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3030 - val_accuracy: 0.0955\n",
      "Epoch 23/30\n",
      "42000/42000 [==============================] - 8s 188us/sample - loss: 2.3028 - accuracy: 0.0999 - val_loss: 2.3028 - val_accuracy: 0.0955\n",
      "Epoch 24/30\n",
      "42000/42000 [==============================] - 8s 200us/sample - loss: 2.3028 - accuracy: 0.1003 - val_loss: 2.3027 - val_accuracy: 0.0955\n",
      "Epoch 25/30\n",
      "42000/42000 [==============================] - 7s 176us/sample - loss: 2.3028 - accuracy: 0.1012 - val_loss: 2.3028 - val_accuracy: 0.0955\n",
      "Epoch 26/30\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 2.3028 - accuracy: 0.1005 - val_loss: 2.3028 - val_accuracy: 0.0955\n",
      "Epoch 27/30\n",
      "42000/42000 [==============================] - 8s 184us/sample - loss: 2.3028 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.1002\n",
      "Epoch 28/30\n",
      "42000/42000 [==============================] - 8s 189us/sample - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3028 - val_accuracy: 0.0955\n",
      "Epoch 29/30\n",
      "42000/42000 [==============================] - 8s 183us/sample - loss: 2.3028 - accuracy: 0.0994 - val_loss: 2.3029 - val_accuracy: 0.0955\n",
      "Epoch 30/30\n",
      "42000/42000 [==============================] - 8s 192us/sample - loss: 2.3028 - accuracy: 0.1016 - val_loss: 2.3029 - val_accuracy: 0.0955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b8a1508288>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=30, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 42us/sample - loss: 2.3029 - accuracy: 0.0955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.302928009668986, 0.0955]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the loss is high and accuracy is very low, we will go with some regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected_model(iterations, lr, Lambda, verb=True):\n",
    "\n",
    "    ## hyperparameters\n",
    "    iterations = iterations\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_nodes, input_shape=(1024,), activation='relu'))\n",
    "    model.add(Dense(hidden_nodes, activation='relu'))\n",
    "    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "    \n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(x_train, y_train, epochs=iterations, batch_size=1000, verbose= 1)\n",
    "    score = model.evaluate(x_train, y_train, verbose=0)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 1s 17us/sample - loss: 2.2981 - accuracy: 0.1265\n"
     ]
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "Lambda = 0\n",
    "score,cm = fully_connected_model(1, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### still there is no improvement, Loss barely changing. Learning rate is probably too low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running with lr=0.02 and Lambda=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 22us/sample - loss: 2.3024 - accuracy: 0.1212\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 0s 11us/sample - loss: 2.1290 - accuracy: 0.2894\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 0s 11us/sample - loss: 1.7593 - accuracy: 0.4275\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 0s 11us/sample - loss: 1.5133 - accuracy: 0.5302\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 0s 11us/sample - loss: 1.3652 - accuracy: 0.5818\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 0s 12us/sample - loss: 1.2646 - accuracy: 0.6162\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 0s 12us/sample - loss: 1.2001 - accuracy: 0.6355\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 0s 11us/sample - loss: 1.1275 - accuracy: 0.6622\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 1.0851 - accuracy: 0.6726\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 0s 11us/sample - loss: 1.0480 - accuracy: 0.6847\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 0s 12us/sample - loss: 1.0199 - accuracy: 0.6918\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 0s 11us/sample - loss: 0.9880 - accuracy: 0.7015\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 0.9525 - accuracy: 0.7139\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 0.9320 - accuracy: 0.7190\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.9134 - accuracy: 0.7253\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 0.8918 - accuracy: 0.7310\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 16us/sample - loss: 0.8651 - accuracy: 0.7385\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 18us/sample - loss: 0.8523 - accuracy: 0.7448\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 0.8386 - accuracy: 0.7472\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8262 - accuracy: 0.7506\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.8076 - accuracy: 0.7572\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 0.8005 - accuracy: 0.7589\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 0.7772 - accuracy: 0.7656\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 0.7625 - accuracy: 0.7717\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.7576 - accuracy: 0.7739\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.7370 - accuracy: 0.7812\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 0.7245 - accuracy: 0.7848\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 0.7223 - accuracy: 0.7850\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 0s 12us/sample - loss: 0.7114 - accuracy: 0.7865\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 0.7152 - accuracy: 0.7860\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 0.7054 - accuracy: 0.7881\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 0.6863 - accuracy: 0.7950\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.7940\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 12us/sample - loss: 0.6655 - accuracy: 0.8030\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 16us/sample - loss: 0.6660 - accuracy: 0.8020\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 0.6553 - accuracy: 0.8048\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.6480 - accuracy: 0.8095\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.6424 - accuracy: 0.8097s - loss: 0.6513 - accura\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.6435 - accuracy: 0.8105\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 0.6319 - accuracy: 0.8131\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.6311 - accuracy: 0.8125\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.6195 - accuracy: 0.8177\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.6278 - accuracy: 0.8144\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.6050 - accuracy: 0.8227\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.6012 - accuracy: 0.8225\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 0.6057 - accuracy: 0.8211\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.5839 - accuracy: 0.8281\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.5899 - accuracy: 0.8270\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.5909 - accuracy: 0.8268\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.5828 - accuracy: 0.8284\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.5715 - accuracy: 0.8328\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.5748 - accuracy: 0.8325\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.5658 - accuracy: 0.8358\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.5607 - accuracy: 0.8343\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.5605 - accuracy: 0.8359\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.5561 - accuracy: 0.8374\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.5410 - accuracy: 0.8423\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.5395 - accuracy: 0.8426\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.5379 - accuracy: 0.8431\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 0.5341 - accuracy: 0.8440\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.5396 - accuracy: 0.8405\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.5388 - accuracy: 0.8430\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.5331 - accuracy: 0.8456\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.5225 - accuracy: 0.8473\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.5174 - accuracy: 0.8495\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 0.5134 - accuracy: 0.8513\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.5160 - accuracy: 0.8492\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 0.5040 - accuracy: 0.8528\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 0.5091 - accuracy: 0.8500\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 16us/sample - loss: 0.5043 - accuracy: 0.8535\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.5012 - accuracy: 0.8535\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4886 - accuracy: 0.8579\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4866 - accuracy: 0.8585\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4885 - accuracy: 0.8579\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4857 - accuracy: 0.8590\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4828 - accuracy: 0.8585\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 0.4823 - accuracy: 0.8601\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4812 - accuracy: 0.8596\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4755 - accuracy: 0.8613\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4702 - accuracy: 0.8634\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4717 - accuracy: 0.8628\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4670 - accuracy: 0.8640\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4582 - accuracy: 0.8667\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4605 - accuracy: 0.8671\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4606 - accuracy: 0.8655\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 13us/sample - loss: 0.4599 - accuracy: 0.8665\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 0.4590 - accuracy: 0.8686s - loss: 0.4523 - \n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 0.4536 - accuracy: 0.8690\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4461 - accuracy: 0.8720\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4450 - accuracy: 0.8717\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4437 - accuracy: 0.8718\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 16us/sample - loss: 0.4439 - accuracy: 0.8703\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4369 - accuracy: 0.8729\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4441 - accuracy: 0.8714\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 15us/sample - loss: 0.4305 - accuracy: 0.8773\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4255 - accuracy: 0.8770\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4308 - accuracy: 0.8745\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4246 - accuracy: 0.8768\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4234 - accuracy: 0.8770\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/sample - loss: 0.4211 - accuracy: 0.8777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42467472266299383, 0.8761905]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 2e-2\n",
    "Lambda = 1e-4\n",
    "fully_connected_model(100, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we can see from above iterations loss is 40% and accuracy is 88%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 88.34 % of testing data was classified correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
